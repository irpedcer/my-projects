{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Exploring Hacker News Posts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This __project__ centers around Hacker News, working with a [dataset](https://www.kaggle.com/hacker-news/hacker-news-posts) of __submissions__ to the site. Specially, we are interested in posts with titles that _begin_ with either _Ask HN_ or _Show HN_:\n",
    "- *Ask HN* is used when users ask the Hacker News community a question.\n",
    "- *Show HN* is used when users want to show the community a project, product or something of the sort. \n",
    "\n",
    "The main __objetive__ of this project is two answer these questions.\n",
    "1. Do Ask HN or Show HN receive more comments on average?\n",
    "2. Do posts creader at a certain time receive more comments on average? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 01. Opening and Exploring the Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#import libraries needed\n",
    "from csv import reader\n",
    "\n",
    "#open and read dataset\n",
    "opened_file = open('hacker_news.csv')\n",
    "read_file = reader(opened_file)\n",
    "hn = list(read_file) #transform the read file into a list of lists\n",
    "\n",
    "#explore data displaying five rows\n",
    "for row in hn[:5]:\n",
    "    print(row)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'url', 'num_points', 'num_comments', 'author', 'created_at']\n",
      "\n",
      "\n",
      "['12224879', 'Interactive Dynamic Video', 'http://www.interactivedynamicvideo.com/', '386', '52', 'ne0phyte', '8/4/2016 11:52']\n",
      "\n",
      "\n",
      "['10975351', 'How to Use Open Source and Shut the Fuck Up at the Same Time', 'http://hueniverse.com/2016/01/26/how-to-use-open-source-and-shut-the-fuck-up-at-the-same-time/', '39', '10', 'josep2', '1/26/2016 19:30']\n",
      "\n",
      "\n",
      "['11964716', \"Florida DJs May Face Felony for April Fools' Water Joke\", 'http://www.thewire.com/entertainment/2013/04/florida-djs-april-fools-water-joke/63798/', '2', '1', 'vezycash', '6/23/2016 22:20']\n",
      "\n",
      "\n",
      "['11919867', 'Technology ventures: From Idea to Enterprise', 'https://www.amazon.com/Technology-Ventures-Enterprise-Thomas-Byers/dp/0073523429', '3', '1', 'hswarna', '6/17/2016 0:01']\n",
      "\n",
      "\n",
      "['10301696', 'Note by Note: The Making of Steinway L1037 (2007)', 'http://www.nytimes.com/2007/11/07/movies/07stein.html?_r=0', '8', '2', 'walterbell', '9/30/2015 4:12']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#removing header and assinging it to a variable\n",
    "header = hn[0]\n",
    "hn=hn[1:]\n",
    "\n",
    "#display to check if everything is correct\n",
    "\n",
    "print(header)         #header\n",
    "print(\"\\n\")\n",
    "\n",
    "for row in hn[:5]:    #data\n",
    "    print(row)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 02. Filtering Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we understand how the data is saved, we need to classify the submissions according to its title. We are only interested in posts beginning with either \"Ask HM\" or \"Show HM\" as explained before. To do that, we will create __three lists__:\n",
    "* A list to save submissions with a title beginning with \"Ask HM\" (ask_posts)\n",
    "* A list to save submissions with a title beginnig with \"Show HM\" (show posts)\n",
    "* A list to save other submissions (other_posts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of 'Ask HM' posts is:  1744\n",
      "The number of 'Show HM' posts is:  1162\n",
      "The number of other posts is:  17194\n"
     ]
    }
   ],
   "source": [
    "#creating the three lists\n",
    "ask_posts=[]\n",
    "show_posts=[]\n",
    "other_posts=[] \n",
    "\n",
    "#classifying the submissions\n",
    "for row in hn:\n",
    "    \n",
    "    title=row[1]                 #saving title into variable\n",
    "    title=title.lower()          #making all the title lowercase to avoid problems using .startswith method\n",
    "    \n",
    "    if title.startswith(\"ask hn\"):  \n",
    "        ask_posts.append(row)   \n",
    "    \n",
    "    elif title.startswith(\"show hn\"):\n",
    "        show_posts.append(row)\n",
    "    \n",
    "    else:\n",
    "        other_posts.append(row)\n",
    "        \n",
    "#cheking length\n",
    "print(\"The number of 'Ask HM' posts is: \", len(ask_posts))\n",
    "print(\"The number of 'Show HM' posts is: \", len(show_posts))\n",
    "print(\"The number of other posts is: \", len(other_posts))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 03. Checking for Wrong Data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before continuing the analysis, we should check if there is any missing data. In order to do so, we can check if the number of elements/columns in a row equals the number of columns in the header. We'll only do that in the ask_posts and show_post lists: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with missing data on ask_posts list is: []\n",
      "The number of rows with missing data on show_posts list is: []\n"
     ]
    }
   ],
   "source": [
    "#create an empty list to save the rows with missing data \n",
    "missing_data_ask= [] \n",
    "missing_data_show = [] \n",
    "\n",
    "#check the length of every row in the lists \n",
    "\n",
    "total_length = len(header)  #save the total length of the header list\n",
    "n_row = 0                  #to know in which row there's missing data \n",
    "\n",
    "for row in ask_posts:     #loop over ask_posts and check the length\n",
    "    row_length=len(row)\n",
    "    if row_length != total_length:\n",
    "        missing_data_ask.append(n_row)\n",
    "    n_row+=1\n",
    "    \n",
    "print(\"The number of rows with missing data on ask_posts list is:\", missing_data_ask)\n",
    "\n",
    "n_row = 0 \n",
    "for row in show_posts:     #loop over ask_posts and check the length\n",
    "    row_length=len(row)\n",
    "    if row_length != total_length:\n",
    "        missing_data_show.append(n_row)\n",
    "    n_row+=1\n",
    "    \n",
    "print(\"The number of rows with missing data on show_posts list is:\", missing_data_show)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we know there will be no problems further exploring the data. \n",
    "\n",
    "We also can check if there is no data in columns we are interested in (comments and time), we can repeat the same procedure. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of rows with missing comments or datetime on ask_posts list is: []\n",
      "The number of rows with missing comments or datetime on show_posts list is: []\n"
     ]
    }
   ],
   "source": [
    "#create an empty list to save the rows with missing data in comments or time\n",
    "missing_data_ask= [] \n",
    "missing_data_show = [] \n",
    "\n",
    "#check the length of every row in the lists \n",
    "\n",
    "n_row = 0                  #to know in which row there's missing data \n",
    "\n",
    "for row in ask_posts:     #loop over ask_posts and check the length\n",
    "    time = row[6]\n",
    "    comments = row[4]\n",
    "    if time == \"\" or comments ==\"\":\n",
    "        missing_data_ask.append(n_row)\n",
    "    n_row+=1\n",
    "    \n",
    "print(\"The number of rows with missing comments or datetime on ask_posts list is:\", missing_data_ask)\n",
    "\n",
    "n_row = 0 \n",
    "for row in show_posts:     #loop over ask_posts and check the length\n",
    "    time = row[6]\n",
    "    comments = row[4]\n",
    "    if time == \"\" or comments ==\"\":\n",
    "        missing_data_show.append(n_row)\n",
    "    n_row+=1\n",
    "    \n",
    "print(\"The number of rows with missing comments or datetime on show_posts list is:\", missing_data_show) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 04. Popularity by number of comments "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to answer the first question proposed in this project, we need to know the number of comments on average the \"Ask HM\" posts and \"Show HM\" posts have.\n",
    "* We will first loop over both lists to know how many comment in _total_ they have, saving the result in total_ask_comments and total_show_comments respectively. \n",
    "* The we will divided it by the number of posts of each type, easily given using the len() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The average of comments on 'Ask HM' posts is 14.04\n",
      "The average of comments on 'Show HM' posts is 10.32\n"
     ]
    }
   ],
   "source": [
    "#Ask comments\n",
    "total_ask_comments=0\n",
    "\n",
    "for row in ask_posts:\n",
    "    n_comments=int(row[4])\n",
    "    total_ask_comments+=n_comments\n",
    "    \n",
    "avg_ask_comments=total_ask_comments/len(ask_posts)\n",
    "\n",
    "#Show comments\n",
    "total_show_comments=0\n",
    "\n",
    "for row in show_posts:\n",
    "    n_comments=int(row[4])\n",
    "    total_show_comments+=n_comments\n",
    "    \n",
    "avg_show_comments=total_show_comments/len(show_posts)  \n",
    "\n",
    "#Show results\n",
    "print(\"The average of comments on 'Ask HM' posts is %.2f\"%(avg_ask_comments))\n",
    "print(\"The average of comments on 'Show HM' posts is %.2f\"%(avg_show_comments))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Conclusions\n",
    "Ask HM posts have more comments in average than Show HM posts. From this results we could affirm that many people interact more with the ask posts. However, we should see if the amount of comments is distributed evenly before making firmer conclusions. \n",
    "\n",
    "Let's plot the list for each type of post - __To do later__\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Popularity by time posted "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We continue our analysis with only the 'Ask HM' submissions, since they had a high average number of comments. In order to do this, we need to calculate: \n",
    "1. Number of posts submitted in each hour of the day \n",
    "2. Number of comments  in each hour of the day\n",
    "2. Average number of comments received by hour \n",
    "\n",
    "Before calculating all of these, we will use datatime.strptime.\n",
    "\n",
    "_Note_: It is important to know that the format of the created_at is the following: MONTH/DAY/YEAR HOUR:MINUTE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import datatime \n",
    "\n",
    "import datetime as dt \n",
    "\n",
    "#Create a list of lists to save the number of comments and date \n",
    "result_list = [] \n",
    "\n",
    "for row in ask_posts:\n",
    "    comments = row[4]\n",
    "    date = row[6]\n",
    "    result_list.append([date, comments])\n",
    "    \n",
    "\n",
    "#Create two dictionaries to save the number of comments and number of posts in each hour\n",
    "counts_by_hour = {}\n",
    "comments_by_hour = {}\n",
    "\n",
    "for row in result_list:\n",
    "    #save de number of comments and date in variables\n",
    "    comments = int(row[1])\n",
    "    date = row[0]\n",
    "    \n",
    "    #Transform date using datatime  \n",
    "    date= dt.datetime.strptime(date, \"%m/%d/%Y %H:%M\")\n",
    "    date=date.strftime(\"%H\")\n",
    "    \n",
    "    #count the number of comments and counts in each hour \n",
    "    if date in counts_by_hour:             #if hour is a key\n",
    "        counts_by_hour[date]+=1            #add up one \n",
    "    else:\n",
    "        counts_by_hour[date]=1             #if not, equal to one \n",
    "        \n",
    "    if date in comments_by_hour:           #if hour is a key\n",
    "        comments_by_hour[date]+=comments   #add up number of comments\n",
    "    else:\n",
    "        comments_by_hour[date]=comments    #equal to number of comments \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will calculate the average of comments by hour. We will store the results in a list of lists called avg_by_hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 Hours for Ask Posts Comments\n",
      "15:00: 38.59 average comments per post\n",
      "02:00: 23.81 average comments per post\n",
      "20:00: 21.52 average comments per post\n",
      "16:00: 16.80 average comments per post\n",
      "21:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "avg_by_hour=[] #create empty list \n",
    "\n",
    "for hour in comments_by_hour: #this loops over every key in the dictionry \n",
    "    avg_by_hour.append([hour, comments_by_hour[hour]/counts_by_hour[hour]])\n",
    "\n",
    "#Once we have avg_by_hour, to improve visualization, we will sort the rows in descending order\n",
    "#To do that we will first swap the columns\n",
    "\n",
    "swap_avg_by_hour = []  #Empty list where we will store the swapped columns \n",
    "\n",
    "for row in avg_by_hour:\n",
    "    swap_avg_by_hour.append([row[1], row[0]])\n",
    "    \n",
    "sorted_swap = sorted(swap_avg_by_hour, reverse = True)  #We put reverse aas true so the highest value appears the first.\n",
    "\n",
    "#Display the results \n",
    "print(\"Top 5 Hours for Ask Posts Comments\")\n",
    "\n",
    "for row in sorted_swap[:5]:\n",
    "    \n",
    "    time = row[1] \n",
    "    time = dt.datetime.strptime(time, \"%H\") #Convert time to a datetime class\n",
    "    time = time.strftime(\"%H:%M\") #Format to show hours and miutes \n",
    "    \n",
    "    print(\"{0}: {1:.2f} average comments per post\".format(time, row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before making our conclusions, we'll convert this to CET (Central European Time) which is 6 hours more than EST.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21:00: 38.59 average comments per post\n",
      "08:00: 23.81 average comments per post\n",
      "02:00: 21.52 average comments per post\n",
      "22:00: 16.80 average comments per post\n",
      "03:00: 16.01 average comments per post\n"
     ]
    }
   ],
   "source": [
    "for row in sorted_swap[:5]:\n",
    "    \n",
    "    time = row[1] \n",
    "    time = dt.datetime.strptime(time, \"%H\") #Convert time to a datetime class\n",
    "    time = time + timedelta(hours=6) #Use timedelta to define a period of time \n",
    "    time = time.strftime(\"%H:%M\") #Format to show hours and miutes \n",
    "    \n",
    "    print(\"{0}: {1:.2f} average comments per post\".format(time, row[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 05. Conclusions\n",
    "We can say the best time to post an Ask Post is at 3 PM EST (9 PM CET), with an average of 38.59 per post. This value is way superior than the others, almost doubling them. So it would definetly be recommended to update at that time. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
